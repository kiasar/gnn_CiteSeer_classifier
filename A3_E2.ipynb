{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiasar/gnn_CiteSeer_classifier/blob/main/A3_E2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install yacs\n",
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "_3NxOt1986yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWFKAejG54BK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "from torch_geometric import nn\n",
        "from torch_geometric.graphgym import optim\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import GINConv\n",
        "from torch_geometric.nn import MLP\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(torch.__version__)\n",
        "print(matplotlib.__version__)\n",
        "print(np.__version__)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import torch\n",
        "# emb: (nNodes, hidden_dim)\n",
        "# node_type: (nNodes,). Entries are torch.int64 ranged from 0 to num_class - 1\n",
        "def visualize(emb: torch.tensor, node_type: torch.tensor):\n",
        "  z = TSNE(n_components=2).fit_transform(emb.detach().cpu().numpy())\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.scatter(z[:, 0], z[:, 1], s=70, c=node_type, cmap=\"Set2\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "FQGE2qtK8eN_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 64\n",
        "num_layers = 2\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "hSjB8t5kS47y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 1"
      ],
      "metadata": {
        "id": "wr9GeEs08ZVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CiteSeer\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "dataset = Planetoid(root=\"data/Planetoid\", name='CiteSeer',\n",
        "transform=NormalizeFeatures())\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "data = dataset[0]\n",
        "print(data)\n",
        "## outputs:\n",
        "# Dataset: CiteSeer():\n",
        "# ======================\n",
        "# Number of graphs: 1\n",
        "# Number of features: 3703\n",
        "# Number of classes: 6\n",
        "# Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LogRYVa8Swr",
        "outputId": "475ab3a5-d0d5-4974-c567-ad7f3bd47a45"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: CiteSeer():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 3703\n",
            "Number of classes: 6\n",
            "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphClassifier(torch.nn.Module):\n",
        "    def __init__(self, dataset, hidden_dim):\n",
        "        super(GraphClassifier, self).__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_features, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, dataset.num_classes)\n",
        "\n",
        "    def forward(self, data, do_visualize=False):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        if do_visualize:\n",
        "          visualize(x, data.y)\n",
        "        # x = F.dropout(x, p=0.5, training=self.training)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "uixc9zIT8i52"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphClassifier(dataset, hidden_dim)\n",
        "print(model)\n",
        "model(dataset[0].to(device), do_visualize=True)"
      ],
      "metadata": {
        "id": "gxzXFZl48jDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    label = out.max(1)[1]\n",
        "    label[data.train_mask] = data.y[data.train_mask]\n",
        "    label.requires_grad = False\n",
        "\n",
        "    loss = F.nll_loss(out[data.train_mask], label[data.train_mask])\n",
        "\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "s5t9ZVZJ8i7f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "\n",
        "    outs = {}\n",
        "    for key in ['train', 'val', 'test']:\n",
        "        mask = data[f'{key}_mask']\n",
        "        loss = F.nll_loss(logits[mask], data.y[mask]).item()\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "\n",
        "        outs[f'{key} loss'] = loss\n",
        "        outs[f'{key} acc'] = acc\n",
        "\n",
        "    return outs"
      ],
      "metadata": {
        "id": "6qsnY7Gb8i-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(dataset, model, epochs, optimizer, lossF):\n",
        "    traning_loss, test_acc, train_acc = [], [], []\n",
        "\n",
        "    data = dataset[0].to(device)\n",
        "\n",
        "    val_loss_history = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, optimizer, data)\n",
        "        eval_info = evaluate(model, data)\n",
        "\n",
        "        traning_loss.append(eval_info[\"train loss\"])\n",
        "        train_acc.append(eval_info[\"train acc\"])\n",
        "        test_acc.append(eval_info['test acc'])\n",
        "    \n",
        "    return test_acc, train_acc, traning_loss"
      ],
      "metadata": {
        "id": "b6u9V8w-8jKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphClassifier(dataset, hidden_dim)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "lossF = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "test_acc, train_acc, traning_loss = run(dataset, model,  200,  optimizer, lossF)"
      ],
      "metadata": {
        "id": "i3PeW6Iy8jOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_test_error = [100 - 100*i for i in test_acc]\n",
        "classification_train_error = [100 - 100*i for i in train_acc]"
      ],
      "metadata": {
        "id": "-lFT5TJHqpGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training loss and classification error on training set w.r.t. iteration\n",
        "x_axis = list(range(1,201))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"training loss\")\n",
        "plt.plot(x_axis, traning_loss, label = \"tranin loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XbsztSTy8gSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_axis = list(range(1,201))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Test error precentage\")\n",
        "plt.title(\"classification error test\")\n",
        "plt.plot(x_axis, classification_test_error, label = \"Error precentage\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MFTnK-7n8ga4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_axis = list(range(1,201))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Train error precentage\")\n",
        "plt.title(\"classification error train\")\n",
        "plt.plot(x_axis, classification_train_error, label = \"Error precentage\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yEUJDI60yuSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import torch\n",
        "# emb: (nNodes, hidden_dim)\n",
        "# node_type: (nNodes,). Entries are torch.int64 ranged from 0 to num_class - 1\n",
        "def visualize(emb: torch.tensor, node_type: torch.tensor):\n",
        "  z = TSNE(n_components=2).fit_transform(emb.detach().cpu().numpy())\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.scatter(z[:, 0], z[:, 1], s=70, c=node_type, cmap=\"Set2\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "visualize()"
      ],
      "metadata": {
        "id": "I5UnO4no8ghA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 2"
      ],
      "metadata": {
        "id": "e6XRn9ry2Hyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphClassifier2(torch.nn.Module):\n",
        "    def __init__(self, dataset, hidden_dim):\n",
        "        super(GraphClassifier2, self).__init__()\n",
        "        mlp1 = MLP([dataset.num_features, hidden_dim])\n",
        "        self.conv1 = GINConv(mlp1)\n",
        "        mlp2 = MLP([hidden_dim, dataset.num_classes])\n",
        "        self.conv2 = GINConv(mlp2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        # x = F.dropout(x, p=0.5, training=self.training)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "aUOTLI8A2GVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphClassifier2(dataset, hidden_dim)\n",
        "model.to(device)\n",
        "print(model)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "lossF = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "test_acc, train_acc, traning_loss = run(dataset, model,  200,  optimizer, lossF)"
      ],
      "metadata": {
        "id": "ZcXKNmaL2XK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training loss and classification error on training set w.r.t. iteration\n",
        "x_axis = list(range(1,201))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"training loss\")\n",
        "plt.plot(x_axis, traning_loss, label = \"tranin loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GnWCqVkd2GYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_axis = list(range(1,201))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Train error precentage\")\n",
        "plt.title(\"classification error train\")\n",
        "plt.plot(x_axis, classification_train_error, label = \"Error precentage\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SHmwZNgA2Gb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_axis = list(range(1,201))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Test error precentage\")\n",
        "plt.title(\"classification error test\")\n",
        "plt.plot(x_axis, classification_test_error, label = \"Error precentage\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q4Op0X6p2Gdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 3"
      ],
      "metadata": {
        "id": "xvSGqIiw7N-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MUTAG\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.loader import DataLoader\n",
        "# dataset = KarateClub(transform=NormalizeFeatures())\n",
        "dataset = TUDataset(root='data/TUDataset', name='MUTAG',\n",
        "transform=NormalizeFeatures())\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "print(dataset[0])\n",
        "train_dataset = dataset[: int(len(dataset) * 0.8)]\n",
        "test_dataset = dataset[int(len(dataset) * 0.8): ]\n",
        "print('==== train_dataset =====')\n",
        "print(train_dataset)\n",
        "print('==== test_dataset =====')\n",
        "print(test_dataset)\n",
        "## outputs:\n",
        "# Dataset: MUTAG(188):\n",
        "# ======================\n",
        "# Number of graphs: 188\n",
        "# Number of features: 7\n",
        "# Number of classes: 2\n",
        "# ==== train_dataset =====\n",
        "# MUTAG(150)\n",
        "# ==== test_dataset =====\n",
        "# MUTAG(38)\n",
        "\n",
        "# Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])"
      ],
      "metadata": {
        "id": "0s-Oq30u2GhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphClassifier3(torch.nn.Module):\n",
        "    def __init__(self, dataset, hidden_dim):\n",
        "        super(GraphClassifier3, self).__init__()\n",
        "        mlp1 = MLP([dataset.num_features, hidden_dim])\n",
        "        self.conv1 = GINConv(mlp1)\n",
        "        mlp2 = MLP([hidden_dim, dataset.num_classes])\n",
        "        self.conv2 = GINConv(mlp2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        # x = F.dropout(x, p=0.5, training=self.training)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "HED6XpbL2GjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphClassifier3(dataset, hidden_dim)\n",
        "model.to(device)\n",
        "print(model)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "lossF = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "test_acc, train_acc, traning_loss = run(dataset, model,  200,  optimizer, lossF)"
      ],
      "metadata": {
        "id": "p_l8XRtMPAw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WXYj4rvLQyZx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}